\chapter{Supplementary figures}

\tikzstyle{my-box}=[rectangle,
    draw=hidden-draw,
    rounded corners,
    text opacity=1,
    minimum height=1.5em,
    minimum width=5em,
    inner sep=2pt,
    align=center,
    fill opacity=.5,
    line width=0.8pt,
]
\tikzstyle{leaf}=[my-box, minimum height=1.5em,
    fill=hidden-pink!80, text=black, align=left,font=\normalsize,
    inner xsep=2pt,
    inner ysep=4pt,
    line width=0.8pt,
]

% Fallback for \Description if not provided by the class/package
\providecommand{\Description}[1]{}

\begin{figure*}[!t]
\centering
\resizebox{0.99\linewidth}{!}{
\begin{forest}
    forked edges,
    for tree={
        grow=east,
        reversed=true,
        anchor=base west,
        parent anchor=east,
        child anchor=west,
        base=center,
        font=\footnotesize,
        rectangle,
        draw=hidden-draw,
        rounded corners,
        align=left,
        text centered,
        minimum width=4em,
        edge+={darkgray, line width=1pt},
        s sep=3pt,
        inner xsep=2pt,
        inner ysep=3pt,
        line width=0.8pt,
        ver/.style={rotate=90, child anchor=north, parent anchor=south, anchor=center},
    },
    where level=1{text width=14em,font=\normalsize,}{},
    where level=2{text width=12em,font=\normalsize,}{},
    where level=3{text width=15em,font=\footnotesize,}{},
    [
        Accelerated Sampling for Video Diffusion Model, ver
        [
            Step Distillation
            [
                Distribution Distillation
                [
                    Streaming Distillation, leaf,
                    content={Streaming Distillation\: \cite{https://doi.org/10.48550/arxiv.2509.25161,https://doi.org/10.48550/arxiv.2506.03099,Yin_2025,yin2024slow,https://doi.org/10.48550/arxiv.2511.01266,Zhou_2025,https://doi.org/10.48550/arxiv.2510.08131,https://doi.org/10.48550/arxiv.2407.01392,https://doi.org/10.48550/arxiv.2405.11473,https://doi.org/10.48550/arxiv.2412.14169,https://doi.org/10.48550/arxiv.2506.09350,https://doi.org/10.48550/arxiv.2508.13009,https://doi.org/10.48550/arxiv.2510.02283,lu2025reward,Henschel_2025,https://doi.org/10.48550/arxiv.2506.08009,https://doi.org/10.48550/arxiv.2408.14837,https://doi.org/10.48550/arxiv.2504.13074,Sun_2025,huang2025live,https://doi.org/10.48550/arxiv.2510.03198,https://doi.org/10.48550/arxiv.2506.01380,https://doi.org/10.48550/arxiv.2509.22622,yi2025deep}}
                ]
                [
                    No Streaming Distillation, leaf,
                    content={No Streaming Distillation\: \cite{gu2025blade,karnewar2025neodragon,https://doi.org/10.48550/arxiv.2503.06674,https://doi.org/10.48550/arxiv.2412.05899,https://doi.org/10.48550/arxiv.2510.12747}}
                ]
            ]
            [
                Consistency Distillation, leaf,
                    content={Consistency Distillation\: \cite{https://doi.org/10.48550/arxiv.2406.06890,zhang2025mobilei2v,lv2025dcm,https://doi.org/10.48550/arxiv.2504.11143,https://doi.org/10.48550/arxiv.2312.09109,https://doi.org/10.48550/arxiv.2505.16239,Mao_2025,https://doi.org/10.48550/arxiv.2508.06082,https://doi.org/10.48550/arxiv.2410.05677,Xu_2025,Zhang_2025,https://doi.org/10.48550/arxiv.2412.15689,https://doi.org/10.48550/arxiv.2405.18750,wang2024phased,Liu_2025}}
            ]
            [
                Adversarial distillation
                [
                    Combined distillation, leaf,
                    content={Combined Distillation\: \cite{https://doi.org/10.48550/arxiv.2507.18569,https://doi.org/10.48550/arxiv.2406.04324,https://doi.org/10.48550/arxiv.2503.19462,cheng2025pose,https://doi.org/10.48550/arxiv.2412.06578,https://doi.org/10.48550/arxiv.2403.12706}}
                ]
                [
                    Independent distillation, leaf,
                    content={Independent Distillation\: \cite{https://doi.org/10.48550/arxiv.2501.08316,https://doi.org/10.48550/arxiv.2509.16507}}
                ]
            ]
        ]
        [
            Efficient Attention
            [
                Sparse Attention
                [
                    Dynamic Sparsity, leaf,
                    content={Dynamic Sparsity\: \cite{https://doi.org/10.48550/arxiv.2505.18809,wu2025usv,https://doi.org/10.48550/arxiv.2510.02617,https://doi.org/10.48550/arxiv.2506.23858,https://doi.org/10.48550/arxiv.2502.01776,shmilovich2025liteattention,https://doi.org/10.48550/arxiv.2509.01085,https://doi.org/10.48550/arxiv.2505.14708,https://doi.org/10.48550/arxiv.2510.18692,https://doi.org/10.48550/arxiv.2508.21058,https://doi.org/10.48550/arxiv.2505.18875,https://doi.org/10.48550/arxiv.2509.16518,https://doi.org/10.48550/arxiv.2502.21079,https://doi.org/10.48550/arxiv.2505.13389,sparge_attn,https://doi.org/10.48550/arxiv.2412.20404,https://doi.org/10.48550/arxiv.2505.22918}}
                ]
                [
                    Static Sparsity, leaf,
                    content={Static Sparsity\: \cite{https://doi.org/10.48550/arxiv.2312.06662,https://doi.org/10.48550/arxiv.2506.19852,https://doi.org/10.48550/arxiv.2506.16054,https://doi.org/10.48550/arxiv.2502.06155,https://doi.org/10.48550/arxiv.2506.03065,Wu_2023,Ruan_2023,Lin_2022}}
                ]
            ]
            [
                Linear Attention
                [
                    Training-based, leaf,
                    content={Training-Based\: \cite{https://doi.org/10.48550/arxiv.2509.24695,huang2025linvideo,https://doi.org/10.48550/arxiv.2509.24006}}
                ]
                [
                    Training-free, leaf,
                    content={Training-Free\: \cite{}}
                ]
            ]
        ]
        [
            Model Compression
            [
                Model Quantization
                [
                    Quantization-aware training, leaf,
                    content={Quantization-Aware Training\: \cite{https://doi.org/10.48550/arxiv.2509.23681,https://doi.org/10.48550/arxiv.2505.11497,https://doi.org/10.48550/arxiv.2506.04648,https://doi.org/10.48550/arxiv.2505.22167,https://doi.org/10.48550/arxiv.2503.06564,feng2025s}}
                ]
                [
                    Post-training quantization, leaf,
                    content={Post-Training Quantization\: \cite{https://doi.org/10.48550/arxiv.2505.18663,Chen_2025,https://doi.org/10.48550/arxiv.2406.02540}}
                ]
            ]
            [
                Model Pruning
                [
                    Token/frame pruning, leaf,
                    content={Token/Frame Pruning\: \cite{https://doi.org/10.48550/arxiv.2412.11706,Piergiovanni_2023}}
                ]
                [
                    Channel/head pruning, leaf,
                    content={Channel/Head Pruning\: \cite{https://doi.org/10.48550/arxiv.2412.07583}}
                ]
            ]
        ]
        [
            System \& Trajectory Tricks
            [
                Caching / Reuse
                [
                    KV/feature caching, leaf,
                    content={KV/Feature Caching\: \cite{https://doi.org/10.48550/arxiv.2510.05367,https://doi.org/10.48550/arxiv.2411.16375,https://doi.org/10.48550/arxiv.2507.02860,https://doi.org/10.48550/arxiv.2406.10981,https://doi.org/10.48550/arxiv.2408.12588,Ceylan_2023,https://doi.org/10.48550/arxiv.2411.02397,https://doi.org/10.48550/arxiv.2410.19355}}
                ]
                [
                    Streaming cache reuse, leaf,
                    content={Streaming Cache Reuse\: \cite{feng2025streamdiffusionv2}}
                ]
            ]
            [
                Latent Trajectory Tricks
                [
                    Noise rescheduling, leaf,
                    content={Noise Rescheduling\: \cite{https://doi.org/10.48550/arxiv.2310.15169}}
                ]
                [
                    Latent shift/trajectory simplification, leaf,
                    content={Latent Shift/Trajectory Simplification\: \cite{https://doi.org/10.48550/arxiv.2307.10373,https://doi.org/10.48550/arxiv.2304.08477,https://doi.org/10.48550/arxiv.2403.14148,https://doi.org/10.48550/arxiv.2503.18940}}
                ]
                [
                    Parallel/patch composition, leaf,
                    content={Parallel/Patch Composition\: \cite{Zhang_2023,https://doi.org/10.48550/arxiv.2305.13077}}
                ]
            ]
            [
                Flow/Score Matching
                [
                    Flow matching sampling, leaf,
                    content={Flow Matching Sampling\: \cite{https://doi.org/10.48550/arxiv.2410.05954,https://doi.org/10.48550/arxiv.2502.05179}}
                ]
            ]
            [
                Other efficiency tricks, leaf,
                content={Other Efficiency Tricks\: \cite{https://doi.org/10.48550/arxiv.2504.12027,https://doi.org/10.48550/arxiv.2501.00103,https://doi.org/10.48550/arxiv.2211.11018,Zhang_2025}}
            ]
            [
                TBD, leaf,
                content={TBD\: \cite{https://doi.org/10.48550/arxiv.2204.03458,Ma_2025,https://doi.org/10.48550/arxiv.2309.09777,Yang_2023,Ma_2025,Shrivastava_2024,ghafoorian2025attention,Esser_2023,https://doi.org/10.48550/arxiv.2502.07701}}
            ]
        ]
    ]
\end{forest}

}
\caption{Taxonomy of accelerated sampling methods for video diffusion models based on the classified corpus (leaves show representative examples; citations to be added).}
\Description{A tree summarizing step distillation families, attention efficiency, model compression, caching/trajectory techniques, and related efficiency tricks for video diffusion models.}
\label{fig:video-accel-taxonomy}
\end{figure*}
